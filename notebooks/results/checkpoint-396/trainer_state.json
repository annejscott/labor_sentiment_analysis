{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 396,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.07575757575757576,
      "grad_norm": 6.180790901184082,
      "learning_rate": 1.9494949494949496e-05,
      "loss": 1.0246,
      "step": 10
    },
    {
      "epoch": 0.15151515151515152,
      "grad_norm": 7.70405387878418,
      "learning_rate": 1.8989898989898993e-05,
      "loss": 0.9633,
      "step": 20
    },
    {
      "epoch": 0.22727272727272727,
      "grad_norm": 10.537549018859863,
      "learning_rate": 1.8484848484848487e-05,
      "loss": 0.983,
      "step": 30
    },
    {
      "epoch": 0.30303030303030304,
      "grad_norm": 3.4349822998046875,
      "learning_rate": 1.797979797979798e-05,
      "loss": 0.9486,
      "step": 40
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 3.660184621810913,
      "learning_rate": 1.7474747474747475e-05,
      "loss": 0.8945,
      "step": 50
    },
    {
      "epoch": 0.45454545454545453,
      "grad_norm": 6.397351264953613,
      "learning_rate": 1.6969696969696972e-05,
      "loss": 0.9968,
      "step": 60
    },
    {
      "epoch": 0.5303030303030303,
      "grad_norm": 3.283048391342163,
      "learning_rate": 1.6464646464646466e-05,
      "loss": 1.0389,
      "step": 70
    },
    {
      "epoch": 0.6060606060606061,
      "grad_norm": 5.859060287475586,
      "learning_rate": 1.595959595959596e-05,
      "loss": 0.9613,
      "step": 80
    },
    {
      "epoch": 0.6818181818181818,
      "grad_norm": 4.006072521209717,
      "learning_rate": 1.5454545454545454e-05,
      "loss": 0.989,
      "step": 90
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 6.259837627410889,
      "learning_rate": 1.4949494949494952e-05,
      "loss": 0.9185,
      "step": 100
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 4.240743160247803,
      "learning_rate": 1.4444444444444446e-05,
      "loss": 1.0707,
      "step": 110
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 4.7179155349731445,
      "learning_rate": 1.3939393939393942e-05,
      "loss": 1.011,
      "step": 120
    },
    {
      "epoch": 0.9848484848484849,
      "grad_norm": 3.596081018447876,
      "learning_rate": 1.3434343434343436e-05,
      "loss": 0.9903,
      "step": 130
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.9830149412155151,
      "eval_runtime": 29.8044,
      "eval_samples_per_second": 8.891,
      "eval_steps_per_second": 1.141,
      "step": 132
    },
    {
      "epoch": 1.0606060606060606,
      "grad_norm": 2.4713938236236572,
      "learning_rate": 1.2929292929292931e-05,
      "loss": 1.0235,
      "step": 140
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 2.539842367172241,
      "learning_rate": 1.2424242424242425e-05,
      "loss": 0.9829,
      "step": 150
    },
    {
      "epoch": 1.2121212121212122,
      "grad_norm": 3.476973533630371,
      "learning_rate": 1.191919191919192e-05,
      "loss": 0.9567,
      "step": 160
    },
    {
      "epoch": 1.2878787878787878,
      "grad_norm": 5.59661865234375,
      "learning_rate": 1.1414141414141415e-05,
      "loss": 1.068,
      "step": 170
    },
    {
      "epoch": 1.3636363636363638,
      "grad_norm": 3.5393593311309814,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 1.0023,
      "step": 180
    },
    {
      "epoch": 1.4393939393939394,
      "grad_norm": 5.222990036010742,
      "learning_rate": 1.0404040404040405e-05,
      "loss": 0.9332,
      "step": 190
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 3.184427499771118,
      "learning_rate": 9.8989898989899e-06,
      "loss": 0.8812,
      "step": 200
    },
    {
      "epoch": 1.5909090909090908,
      "grad_norm": 2.643828868865967,
      "learning_rate": 9.393939393939396e-06,
      "loss": 0.9933,
      "step": 210
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 6.812561988830566,
      "learning_rate": 8.888888888888888e-06,
      "loss": 1.0486,
      "step": 220
    },
    {
      "epoch": 1.7424242424242424,
      "grad_norm": 4.937647342681885,
      "learning_rate": 8.383838383838384e-06,
      "loss": 0.9429,
      "step": 230
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 3.967308521270752,
      "learning_rate": 7.87878787878788e-06,
      "loss": 0.9979,
      "step": 240
    },
    {
      "epoch": 1.893939393939394,
      "grad_norm": 2.058410406112671,
      "learning_rate": 7.373737373737374e-06,
      "loss": 0.944,
      "step": 250
    },
    {
      "epoch": 1.9696969696969697,
      "grad_norm": 4.910506248474121,
      "learning_rate": 6.868686868686869e-06,
      "loss": 0.9707,
      "step": 260
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.9684506058692932,
      "eval_runtime": 31.0305,
      "eval_samples_per_second": 8.54,
      "eval_steps_per_second": 1.096,
      "step": 264
    },
    {
      "epoch": 2.0454545454545454,
      "grad_norm": 6.061112403869629,
      "learning_rate": 6.363636363636364e-06,
      "loss": 1.0659,
      "step": 270
    },
    {
      "epoch": 2.121212121212121,
      "grad_norm": 3.2398083209991455,
      "learning_rate": 5.858585858585859e-06,
      "loss": 0.9926,
      "step": 280
    },
    {
      "epoch": 2.196969696969697,
      "grad_norm": 3.6849136352539062,
      "learning_rate": 5.353535353535354e-06,
      "loss": 0.9473,
      "step": 290
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 2.412933111190796,
      "learning_rate": 4.848484848484849e-06,
      "loss": 0.9115,
      "step": 300
    },
    {
      "epoch": 2.3484848484848486,
      "grad_norm": 7.528298854827881,
      "learning_rate": 4.343434343434344e-06,
      "loss": 1.0707,
      "step": 310
    },
    {
      "epoch": 2.4242424242424243,
      "grad_norm": 2.6718850135803223,
      "learning_rate": 3.8383838383838385e-06,
      "loss": 0.9221,
      "step": 320
    },
    {
      "epoch": 2.5,
      "grad_norm": 3.609076499938965,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.9357,
      "step": 330
    },
    {
      "epoch": 2.5757575757575757,
      "grad_norm": 6.547508239746094,
      "learning_rate": 2.8282828282828286e-06,
      "loss": 1.0159,
      "step": 340
    },
    {
      "epoch": 2.6515151515151514,
      "grad_norm": 2.826096534729004,
      "learning_rate": 2.3232323232323234e-06,
      "loss": 0.9081,
      "step": 350
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 2.5229358673095703,
      "learning_rate": 1.8181818181818183e-06,
      "loss": 0.9226,
      "step": 360
    },
    {
      "epoch": 2.8030303030303028,
      "grad_norm": 6.244053840637207,
      "learning_rate": 1.3131313131313134e-06,
      "loss": 0.9869,
      "step": 370
    },
    {
      "epoch": 2.878787878787879,
      "grad_norm": 2.713515281677246,
      "learning_rate": 8.080808080808082e-07,
      "loss": 0.9789,
      "step": 380
    },
    {
      "epoch": 2.9545454545454546,
      "grad_norm": 7.009163856506348,
      "learning_rate": 3.0303030303030305e-07,
      "loss": 0.9933,
      "step": 390
    }
  ],
  "logging_steps": 10,
  "max_steps": 396,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 833543307362304.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
